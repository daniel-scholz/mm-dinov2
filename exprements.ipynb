{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import argparse\n",
    "import math\n",
    "import IPython \n",
    "from PIL import Image\n",
    "from enum import Enum\n",
    "from typing import Callable, List, Optional, Tuple, Union\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.datasets import VisionDataset\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt \n",
    "import torchxrayvision as xrv\n",
    "\n",
    "from fvcore.common.checkpoint import Checkpointer, PeriodicCheckpointer\n",
    "import dinov2.distributed as distributed\n",
    "from dinov2.models.unet import UNet\n",
    "from dinov2.data import SamplerType, make_data_loader, make_dataset\n",
    "from dinov2.data.datasets import NIHChestXray, MC, Shenzhen, SARSCoV2CT\n",
    "from dinov2.data.datasets.medical_dataset import MedicalVisionDataset\n",
    "from dinov2.data.loaders import make_data_loader\n",
    "from dinov2.data.transforms import (make_segmentation_train_transforms, make_classification_eval_transform, make_segmentation_eval_transforms,\n",
    "                                    make_classification_train_transform)\n",
    "from dinov2.eval.setup import setup_and_build_model\n",
    "from dinov2.eval.utils import (is_zero_matrix, ModelWithIntermediateLayers, ModelWithNormalize, evaluate, extract_features, collate_fn_3d,\n",
    "                               make_datasets)\n",
    "from dinov2.eval.classification.utils import LinearClassifier, create_linear_input, setup_linear_classifiers, AllClassifiers\n",
    "from dinov2.eval.metrics import build_segmentation_metrics\n",
    "from dinov2.eval.segmentation.utils import LinearDecoder, setup_decoders\n",
    "from dinov2.utils import show_image_from_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(config_file='dinov2/configs/eval/vits14_pretrain.yaml', pretrained_weights='models/dinov2_vits14_pretrain.pth', output_dir='results/NIH/dinov2_vits14/knn', opts=[], train_dataset_str='Shenzhen:split=TRAIN:root=/mnt/z/data/Shenzhen', val_dataset_str='Shenzhen:split=VAL:root=/mnt/z/data/Shenzhen', test_dataset_str='Shenzhen:split=TEST:root=/mnt/z/data/Shenzhen', nb_knn=[5, 20, 50, 100, 200], temperature=0.07, gather_on_cpu=False, batch_size=8, n_per_class_list=[-1], n_tries=1, ngpus=1, nodes=1, timeout=2800, partition='learnlab', use_volta32=False, comment='', exclude='')\n",
    "model, autocast_dtype = setup_and_build_model(args)\n",
    "autocast_ctx = partial(torch.cuda.amp.autocast, enabled=True, dtype=autocast_dtype)\n",
    "feature_model = ModelWithIntermediateLayers(model, 1, autocast_ctx, is_3d=True)\n",
    "# model = ModelWithNormalize(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_str = args.train_dataset_str\n",
    "val_dataset_str = args.val_dataset_str\n",
    "batch_size = args.batch_size\n",
    "gather_on_cpu = args.gather_on_cpu\n",
    "num_workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Split(Enum):\n",
    "    TRAIN = \"train\"\n",
    "    VAL = \"val\"\n",
    "    TEST = \"test\"\n",
    "\n",
    "    @property\n",
    "    def length(self) -> int:\n",
    "        split_lengths = {\n",
    "            _Split.TRAIN: 90,\n",
    "            _Split.VAL: 50,\n",
    "            _Split.TEST: 70,\n",
    "        }\n",
    "        return split_lengths[self]\n",
    "\n",
    "class SARSCoV2CT(MedicalVisionDataset):\n",
    "    Split = _Split\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        split: \"SARSCoV2CT.Split\",\n",
    "        root: str,\n",
    "        transforms: Optional[Callable] = None,\n",
    "        transform: Optional[Callable] = None,\n",
    "        target_transform: Optional[Callable] = None,\n",
    "    ) -> None:\n",
    "        super().__init__(split, root, transforms, transform, target_transform)\n",
    "\n",
    "        self.class_names = [\n",
    "            \"Negative\",\n",
    "            \"Positive\"\n",
    "        ]\n",
    "        \n",
    "    @property\n",
    "    def split(self) -> \"SARSCoV2CT.Split\":\n",
    "        return self._split\n",
    "\n",
    "    def get_length(self) -> int:\n",
    "        return self.__len__()\n",
    "\n",
    "    def get_num_classes(self) -> int:\n",
    "        return 2\n",
    "    \n",
    "    def is_3d(self) -> bool:\n",
    "        return True\n",
    "    \n",
    "    def is_multilabel(self) -> bool:\n",
    "        return False\n",
    "\n",
    "    def get_image_data(self, index: int) -> np.ndarray:\n",
    "        scans_path = self._split_dir + os.sep + self.images[index]\n",
    "        scans = os.listdir(scans_path)\n",
    "        scans = [\".\".join(scan.split(\".\")[:-1]) for scan in scans]\n",
    "        \n",
    "        if scans[0].isnumeric():\n",
    "            scans = [int(scan) for scan in scans]\n",
    "            scans.sort()\n",
    "\n",
    "        for i, scan in enumerate(scans):\n",
    "            \n",
    "            scan = skimage.io.imread(scans_path + os.sep + str(scan) + \".png\")\n",
    "            scan = scan[:, :, :3]\n",
    "            scan = torch.from_numpy(scan).permute(2, 0, 1).float()\n",
    "\n",
    "            scans[i] = scan \n",
    "\n",
    "        return scans\n",
    "    \n",
    "    def get_target(self, index: int) -> int:\n",
    "        return int(int(self.images[index]) <= 79) # IDs 0-79 are positive\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        images = self.get_image_data(index)\n",
    "        target = self.get_target(index)\n",
    "\n",
    "        seed = np.random.randint(2147483647) # make a seed with numpy generator \n",
    "        if self.transforms is not None:\n",
    "            for i in range(len(images)):\n",
    "                np.random.seed(seed), torch.manual_seed(seed) \n",
    "                images[i] = self.transform(images[i])\n",
    "            images = torch.stack(images, dim=0)\n",
    "\n",
    "        return images, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, l = make_segmentation_train_transforms(resize_size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = target_transform = make_classification_train_transform()\n",
    "dataset = SARSCoV2CT(split=SARSCoV2CT.Split.TRAIN,\n",
    "                root=\"/mnt/z/data/SARS-CoV-2-CT\",\n",
    "                transform=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in dataset:\n",
    "    i.cuda()\n",
    "    show_image_from_tensor(i[0])\n",
    "    show_image_from_tensor(i[1])\n",
    "    show_image_from_tensor(i[2])\n",
    "    show_image_from_tensor(i[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform(torch.concat(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = make_data_loader(\n",
    "    dataset=dataset,\n",
    "    collate_fn=collate_fn_3d,\n",
    "    batch_size=4,\n",
    "    num_workers=1,\n",
    "    shuffle=True,\n",
    "    seed=0,\n",
    "    sampler_type=None,\n",
    "    sampler_advance=1,\n",
    "    drop_last=False,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier(nn.Module):\n",
    "    \"\"\"Linear layer to train on top of frozen features\"\"\"\n",
    "\n",
    "    def __init__(self, out_dim, use_n_blocks, use_avgpool, num_classes=1000, is_3d=False):\n",
    "        super().__init__()\n",
    "        self.out_dim = out_dim\n",
    "        self.use_n_blocks = use_n_blocks\n",
    "        self.use_avgpool = use_avgpool\n",
    "        self.num_classes = num_classes\n",
    "        self.linear = nn.Linear(out_dim, num_classes)\n",
    "        self.linear.weight.data.normal_(mean=0.0, std=0.01)\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.is_3d = is_3d\n",
    "\n",
    "    def forward_3d(self, inputs):\n",
    "        outputs_per_batch = []\n",
    "        for batch in inputs:\n",
    "            outputs_per_batch.append(self.forward_(batch))\n",
    "        outputs = torch.stack(outputs_per_batch).squeeze()\n",
    "        return outputs\n",
    "    \n",
    "    def forward_(self, inputs):\n",
    "        output = torch.stack( # If 3D, take average of all slices.\n",
    "            [create_linear_input(image, self.use_n_blocks, self.use_avgpool) for image in inputs]\n",
    "            ).mean(dim=0)\n",
    "        return output.squeeze()\n",
    "    \n",
    "    def forward(self, images):\n",
    "        if self.is_3d: output = self.forward_3d(images)\n",
    "        else: output = self.forward_(images)\n",
    "\n",
    "        return self.linear(output).squeeze()\n",
    "\n",
    "lc = LinearClassifier(384, 1, False, 1, is_3d=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_output = feature_model.forward_(dataset[0][0][0].unsqueeze(0).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_linear_classifiers(sample_output, n_last_blocks_list, learning_rates, avgpools=[True, False], num_classes=14, is_3d=False):\n",
    "    \"\"\"\n",
    "    Sets up the multiple linear classifiers with different hyperparameters to test out the most optimal one \n",
    "    \"\"\"\n",
    "    linear_classifiers_dict = nn.ModuleDict()\n",
    "    optim_param_groups = []\n",
    "    for n in n_last_blocks_list:\n",
    "        for avgpool in avgpools:\n",
    "            for _lr in learning_rates:\n",
    "                # lr = scale_lr(_lr, batch_size)\n",
    "                lr = _lr\n",
    "                out_dim = create_linear_input(sample_output, use_n_blocks=n, use_avgpool=avgpool).shape[1]\n",
    "                linear_classifier = LinearClassifier(\n",
    "                    out_dim, use_n_blocks=n, use_avgpool=avgpool, num_classes=num_classes, is_3d=is_3d\n",
    "                )\n",
    "                linear_classifier = linear_classifier.cuda()\n",
    "                linear_classifiers_dict[\n",
    "                    f\"linear:blocks={n}:avgpool={avgpool}:lr={lr:.10f}\".replace(\".\", \"_\")\n",
    "                ] = linear_classifier\n",
    "                optim_param_groups.append({\"params\": linear_classifier.parameters(), \"lr\": lr})\n",
    "\n",
    "    linear_classifiers = AllClassifiers(linear_classifiers_dict)\n",
    "    if distributed.is_enabled():\n",
    "        linear_classifiers = nn.parallel.DistributedDataParallel(linear_classifiers)\n",
    "\n",
    "    return linear_classifiers, optim_param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_classifiers, optim_param_groups = setup_linear_classifiers(\n",
    "    sample_output=sample_output,\n",
    "    n_last_blocks_list=[1, 4],\n",
    "    learning_rates=[1e-2, 1e-4],\n",
    "    avgpools=[False, True],\n",
    "    num_classes=1,\n",
    "    is_3d=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AllClassifiers(nn.Module):\n",
    "    def __init__(self, classifiers_dict):\n",
    "        super().__init__()\n",
    "        self.classifiers_dict = nn.ModuleDict()\n",
    "        self.classifiers_dict.update(classifiers_dict)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        print(inputs)\n",
    "        print(\"1\")\n",
    "        return {k: v.forward(inputs) for k, v in self.classifiers_dict.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.classifiers_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 0\n",
    "f = 0\n",
    "for i, t in train_data_loader:\n",
    "    i = i.cuda()\n",
    "    t = t.cuda()\n",
    "\n",
    "    features = feature_model(i)  # batch then slices\n",
    "    # output = lc(features)\n",
    "    output = linear_classifiers(features)\n",
    "    break\n",
    "\n",
    "    # outputs = [\n",
    "    #     list(self.all_classifiers_forward(batch_feature).values()) for batch_feature in inputs\n",
    "    #     ]\n",
    "    # classifier_outputs = [torch.stack(output).squeeze() for output in outputs] # stack across classifiers\n",
    "    # outputs = torch.stack(classifier_outputs, dim=1) # stack across batch\n",
    "    # classifiers = list(self.classifiers_dict.keys())\n",
    "    # outputs = { # output for every classifer\n",
    "    #     classifiers[i]: output \n",
    "    #     for i, output in enumerate(outputs)\n",
    "    # }\n",
    "    # return outputs\n",
    "    break\n",
    "    outputs = [lc(batch_feature) for batch_feature in batch_features]\n",
    "    outputs = torch.stack(outputs, dim=0).squeeze(1)\n",
    "    print(outputs)\n",
    "    break\n",
    "    if z == 5:\n",
    "        break\n",
    "    z+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_transform, train_target_transform = make_segmentation_train_transforms()\n",
    "eval_image_transform, eval_target_transform  = make_segmentation_eval_transforms()\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = make_datasets(train_dataset_str=train_dataset_str, val_dataset_str=val_dataset_str,\n",
    "                                                        test_dataset_str=args.test_dataset_str, train_transform=train_image_transform,\n",
    "                                                        eval_transform=eval_image_transform, train_target_transform=train_target_transform,\n",
    "                                                        eval_target_transform=eval_target_transform)\n",
    "\n",
    "sampler_type = SamplerType.INFINITE\n",
    "\n",
    "train_data_loader = make_data_loader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=8,\n",
    "    num_workers=1,\n",
    "    shuffle=True,\n",
    "    seed=0,\n",
    "    sampler_type=sampler_type,\n",
    "    sampler_advance=1,\n",
    "    drop_last=False,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "val_data_loader = make_data_loader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=4,\n",
    "    num_workers=1,\n",
    "    shuffle=True,\n",
    "    seed=0,\n",
    "    sampler_type=sampler_type,\n",
    "    sampler_advance=1,\n",
    "    drop_last=False,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in train_dataset:\n",
    "    i.cuda() \n",
    "    t.cuda()\n",
    "    \n",
    "    print(i.shape)\n",
    "\n",
    "    show_image_from_tensor(i)\n",
    "    show_image_from_tensor(t.unsqueeze(0) * 100)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in train_data_loader:\n",
    "    i = i.cuda()\n",
    "    i = feature_model(i)\n",
    "    print(len(i))\n",
    "    print(len(i[0]))\n",
    "    print(len(i[0][0]))\n",
    "    print(len(i[0][0][0]))\n",
    "    print(len(i[0][0][0][0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearDecoder(torch.nn.Module):\n",
    "    \"\"\"Linear decoder head\"\"\"\n",
    "    DECODER_TYPE = \"linear\"\n",
    "\n",
    "    def __init__(self, in_channels, tokenW=32, tokenH=32, num_classes=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.width = tokenW\n",
    "        self.height = tokenH\n",
    "        self.decoder = torch.nn.Conv2d(in_channels, num_classes, (1,1))\n",
    "        self.decoder.weight.data.normal_(mean=0.0, std=0.01)\n",
    "        self.decoder.bias.data.zero_()\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        print(embeddings.shape)\n",
    "        embeddings = embeddings.reshape(-1, self.height, self.width, self.in_channels)\n",
    "        print(embeddings.shape)\n",
    "        embeddings = embeddings.permute(0,3,1,2)\n",
    "        print(embeddings.shape)\n",
    "\n",
    "        return self.decoder(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = LinearDecoder(384, num_classes=2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in train_dataset:\n",
    "    i = i.cuda().unsqueeze(0)\n",
    "    a = model(i)\n",
    "    b = model.forward_features(i)['x_norm_patchtokens']\n",
    "    z = d(b)\n",
    "    print(z.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated = torch.utils.data.ConcatDataset([train_dataset, val_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(concated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated.get_num_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in concated:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/mnt/d/data/NIH/\"\n",
    "train_val = pd.read_csv(data_dir + os.sep + \"train_val_list.txt\", names=[\"Image Index\"])\n",
    "val_list = [i for i in range(len(train_val)-10_002, len(train_val))]\n",
    "val_set = train_val.iloc[val_list]\n",
    "train_set = train_val.drop(val_list)\n",
    "\n",
    "train_dir = data_dir + os.sep + \"train\"\n",
    "val_dir = data_dir + os.sep + \"val\"\n",
    "for image in val_set[\"Image Index\"]:\n",
    "    source = train_dir + os.sep + image\n",
    "    dest = val_dir + os.sep + image\n",
    "    shutil.move(source, dest)\n",
    "\n",
    "val_set.to_csv(data_dir + os.sep + \"val_list.txt\", index=False, header=False)\n",
    "train_set.to_csv(data_dir + os.sep + \"train_list.txt\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearDecoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, tokenW=32, tokenH=32, num_labels=1):\n",
    "        super(LinearDecoder, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.width = tokenW\n",
    "        self.height = tokenH\n",
    "        self.decoder = torch.nn.Conv2d(in_channels, num_labels, (1,1))\n",
    "        self.decoder.weight.data.normal_(mean=0.0, std=0.01)\n",
    "        self.decoder.bias.data.zero_()\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        embeddings = embeddings.reshape(-1, self.height, self.width, self.in_channels)\n",
    "        embeddings = embeddings.permute(0,3,1,2)\n",
    "\n",
    "        return self.decoder(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = LinearDecoder(384, num_labels=3).cuda()\n",
    "optimizer = torch.optim.SGD(params=decoder.parameters(), lr=0.0005, momentum=0.9, weight_decay=0)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 69, eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricAveraging(Enum):\n",
    "    MEAN_ACCURACY = \"micro\"\n",
    "    MEAN_PER_CLASS_ACCURACY = \"macro\"\n",
    "    MULTILABEL_ACCURACY = \"macro\"\n",
    "    MULTILABEL_AUROC = \"macro\"\n",
    "    MULTILABEL_JACCARD = \"macro\"\n",
    "    PER_CLASS_ACCURACY = \"none\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.value\n",
    "\n",
    "metric = build_segmentation_metrics(average_type=MetricAveraging.MULTILABEL_JACCARD,num_labels=3)\n",
    "metric.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for image, target in train_data_loader:\n",
    "    i+=1\n",
    "    image, target = image.cuda(non_blocking=True), target.cuda(non_blocking=True)\n",
    "    with torch.no_grad(): \n",
    "        features=model.forward_features(image)['x_norm_patchtokens']\n",
    "    logits = decoder(features)\n",
    "    logits = torch.nn.functional.interpolate(logits, size=448, mode=\"bilinear\", align_corners=False)\n",
    "    prediction = logits.argmax(dim=1)\n",
    "\n",
    "    loss_fct = torch.nn.CrossEntropyLoss()\n",
    "    loss = loss_fct(logits, target)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    metric(prediction, target)\n",
    "    print(metric.compute())\n",
    "    print(loss.item())\n",
    "\n",
    "    # if i % 50 == 0:\n",
    "    show_image_from_tensor((prediction * 100).cpu())\n",
    "    show_image_from_tensor((target * 100).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
