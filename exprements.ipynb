{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import IPython \n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt \n",
    "import torchxrayvision as xrv\n",
    "\n",
    "from dinov2.data import SamplerType, make_data_loader, make_dataset\n",
    "from dinov2.data.datasets import NIHChestXray\n",
    "from dinov2.data.transforms import make_xray_classification_eval_transform, make_classification_eval_transform\n",
    "from dinov2.eval.setup import setup_and_build_model\n",
    "from dinov2.eval.utils import ModelWithNormalize, evaluate, extract_features\n",
    "from dinov2.MLkNN import MLkNN \n",
    "from dinov2.utils import show_image_from_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(config_file='dinov2/configs/eval/vits14_pretrain.yaml', pretrained_weights='models/dinov2_vits14_pretrain.pth', output_dir='results/NIH/dinov2_vits14/knn', opts=[], train_dataset_str='NIHChestXray:split=TRAIN:root=/mnt/d/data/NIH/train_tmp', val_dataset_str='NIHChestXray:split=VAL:root=/mnt/d/data/NIH/test_tmp', nb_knn=[5, 20, 50, 100, 200], temperature=0.07, gather_on_cpu=False, batch_size=8, n_per_class_list=[-1], n_tries=1, ngpus=1, nodes=1, timeout=2800, partition='learnlab', use_volta32=False, comment='', exclude='')\n",
    "model, autocast_dtype = setup_and_build_model(args)\n",
    "model = ModelWithNormalize(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = make_classification_eval_transform()\n",
    "train_dataset = make_dataset(\n",
    "    dataset_str=args.train_dataset_str,\n",
    "    transform=transform,\n",
    ")\n",
    "val_dataset = make_dataset(\n",
    "    dataset_str=args.val_dataset_str,\n",
    "    transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_str = args.train_dataset_str\n",
    "val_dataset_str = args.val_dataset_str\n",
    "batch_size = args.batch_size\n",
    "gather_on_cpu = args.gather_on_cpu\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast(dtype=autocast_dtype):\n",
    "    train_features, train_labels = extract_features(\n",
    "        model, train_dataset, batch_size, num_workers, gather_on_cpu=gather_on_cpu\n",
    "    )\n",
    "    val_features, val_labels = extract_features(\n",
    "        model, val_dataset, batch_size, num_workers, gather_on_cpu=gather_on_cpu\n",
    "    )\n",
    "\n",
    "train_features = train_features.cpu().numpy()\n",
    "train_labels = train_labels.cpu().numpy()\n",
    "val_features = val_features.cpu().numpy()\n",
    "val_labels = val_labels.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### for 5-NN ###\n",
      "### Hamming loss: 0.093182\n",
      "### Accuracy score: 0.409091\n",
      "### mAUC score combined: 0.633929\n",
      "### F1 score: 0.481013\n",
      "## Disease-specific AUC scores\n",
      "                         AUC  Accuracy        F1\n",
      "Atelectasis         0.500000  0.954545  0.000000\n",
      "Cardiomegaly        0.500000  0.909091  0.000000\n",
      "Effusion            0.500000  0.863636  0.000000\n",
      "Emphysema           0.500000  0.954545  0.000000\n",
      "Fibrosis            0.500000  0.954545  0.000000\n",
      "Infiltration        0.666667  0.863636  0.500000\n",
      "Mass                0.500000  0.954545  0.000000\n",
      "No Finding          0.772727  0.772727  0.761905\n",
      "Nodule              0.500000  0.909091  0.000000\n",
      "Pleural_Thickening  0.500000  0.931818  0.000000\n",
      "### for 20-NN ###\n",
      "### Hamming loss: 0.104545\n",
      "### Accuracy score: 0.363636\n",
      "### mAUC score combined: 0.589286\n",
      "### F1 score: 0.410256\n",
      "## Disease-specific AUC scores\n",
      "                         AUC  Accuracy        F1\n",
      "Atelectasis         0.500000  0.954545  0.000000\n",
      "Cardiomegaly        0.500000  0.909091  0.000000\n",
      "Effusion            0.500000  0.863636  0.000000\n",
      "Emphysema           0.500000  0.954545  0.000000\n",
      "Fibrosis            0.500000  0.954545  0.000000\n",
      "Infiltration        0.500000  0.795455  0.000000\n",
      "Mass                0.500000  0.954545  0.000000\n",
      "No Finding          0.727273  0.727273  0.727273\n",
      "Nodule              0.500000  0.909091  0.000000\n",
      "Pleural_Thickening  0.500000  0.931818  0.000000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 44, n_neighbors = 50",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m args\u001b[39m.\u001b[39mnb_knn:\n\u001b[1;32m      5\u001b[0m     classifier \u001b[39m=\u001b[39m MLkNN(k)\n\u001b[0;32m----> 6\u001b[0m     classifier\u001b[39m.\u001b[39;49mfit(train_features, train_labels)\n\u001b[1;32m      7\u001b[0m     results \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mpredict(train_features)\u001b[39m.\u001b[39mtoarray()\n\u001b[1;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m### for \u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m-NN ###\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/c/Users/user/Desktop/dinov2/dinov2/MLkNN.py:238\u001b[0m, in \u001b[0;36mMLkNN.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prior_prob_true, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prior_prob_false \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_prior(\n\u001b[1;32m    235\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_label_cache\n\u001b[1;32m    236\u001b[0m )\n\u001b[1;32m    237\u001b[0m \u001b[39m# Computing the posterior probabilities\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cond_prob_true, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cond_prob_false \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_cond(\n\u001b[1;32m    239\u001b[0m     X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_label_cache\n\u001b[1;32m    240\u001b[0m )\n\u001b[1;32m    241\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/mnt/c/Users/user/Desktop/dinov2/dinov2/MLkNN.py:181\u001b[0m, in \u001b[0;36mMLkNN._compute_cond\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    175\u001b[0m cn \u001b[39m=\u001b[39m sparse\u001b[39m.\u001b[39mlil_matrix((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_labels, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mi8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    177\u001b[0m label_info \u001b[39m=\u001b[39m get_matrix_in_format(y, \u001b[39m\"\u001b[39m\u001b[39mdok\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    179\u001b[0m neighbors \u001b[39m=\u001b[39m [\n\u001b[1;32m    180\u001b[0m     a[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mignore_first_neighbours :]\n\u001b[0;32m--> 181\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mknn_\u001b[39m.\u001b[39;49mkneighbors(\n\u001b[1;32m    182\u001b[0m         X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_first_neighbours, return_distance\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    184\u001b[0m ]\n\u001b[1;32m    186\u001b[0m \u001b[39mfor\u001b[39;00m instance \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_instances):\n\u001b[1;32m    187\u001b[0m     deltas \u001b[39m=\u001b[39m label_info[neighbors[instance], :]\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neighbors/_base.py:808\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    806\u001b[0m n_samples_fit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples_fit_\n\u001b[1;32m    807\u001b[0m \u001b[39mif\u001b[39;00m n_neighbors \u001b[39m>\u001b[39m n_samples_fit:\n\u001b[0;32m--> 808\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    809\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExpected n_neighbors <= n_samples, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    810\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m but n_samples = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, n_neighbors = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (n_samples_fit, n_neighbors)\n\u001b[1;32m    811\u001b[0m     )\n\u001b[1;32m    813\u001b[0m n_jobs \u001b[39m=\u001b[39m effective_n_jobs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n\u001b[1;32m    814\u001b[0m chunked_results \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 44, n_neighbors = 50"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "for k in args.nb_knn:\n",
    "    classifier = MLkNN(k)\n",
    "    classifier.fit(train_features, train_labels)\n",
    "    results = classifier.predict(train_features).toarray()\n",
    "    print(f\"### for {k}-NN ###\")\n",
    "    print(\"### Hamming loss: %f\" % sklearn.metrics.hamming_loss(train_labels, results))\n",
    "    print(\"### Accuracy score: %f\" % sklearn.metrics.accuracy_score(train_labels, results))\n",
    "    print(\"### mAUC score combined: %f\" % sklearn.metrics.roc_auc_score(train_labels, results, average=\"weighted\"))\n",
    "    print(\"### F1 score: %f\" % sklearn.metrics.f1_score(train_labels, results, average=\"micro\"))\n",
    "\n",
    "    # Disease-specific scores\n",
    "    disease_results = {\"AUC\": {}, \"Accuracy\": {}, \"F1\": {}}\n",
    "    for index, disease in enumerate(train_dataset.class_names):\n",
    "        disease_results[\"AUC\"][disease] =  sklearn.metrics.roc_auc_score(train_labels[:, index], results[:, index])\n",
    "        disease_results[\"Accuracy\"][disease] =  sklearn.metrics.accuracy_score(train_labels[:, index], results[:, index])\n",
    "        disease_results[\"F1\"][disease] =  sklearn.metrics.f1_score(train_labels[:, index], results[:, index])\n",
    "    print(\"## Disease-specific AUC scores\")    \n",
    "    print(pd.DataFrame(disease_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
