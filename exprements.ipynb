{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import IPython \n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt \n",
    "import torchxrayvision as xrv\n",
    "\n",
    "from dinov2.data import SamplerType, make_data_loader, make_dataset\n",
    "from dinov2.data.datasets import NIHChestXray\n",
    "from dinov2.data.transforms import make_xray_classification_eval_transform, make_classification_eval_transform\n",
    "from dinov2.eval.setup import setup_and_build_model\n",
    "from dinov2.eval.utils import ModelWithNormalize, evaluate, extract_features\n",
    "from dinov2.utils import show_image_from_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I20230813 21:39:27 683 dinov2 config.py:60] git:\n",
      "  sha: e326bc6424a2557c160a3cdb326324ed5f8f1ebe, status: has uncommitted changes, branch: main\n",
      "\n",
      "I20230813 21:39:27 683 dinov2 config.py:61] batch_size: 8\n",
      "comment: \n",
      "config_file: dinov2/configs/eval/vits14_pretrain.yaml\n",
      "exclude: \n",
      "gather_on_cpu: False\n",
      "n_per_class_list: [-1]\n",
      "n_tries: 1\n",
      "nb_knn: [5, 20, 50, 100, 200]\n",
      "ngpus: 1\n",
      "nodes: 1\n",
      "opts: ['train.output_dir=/mnt/c/Users/user/Desktop/dinov2/results/NIH/dinov2_vits14/knn']\n",
      "output_dir: /mnt/c/Users/user/Desktop/dinov2/results/NIH/dinov2_vits14/knn\n",
      "partition: learnlab\n",
      "pretrained_weights: models/dinov2_vits14_pretrain.pth\n",
      "temperature: 0.07\n",
      "timeout: 2800\n",
      "train_dataset_str: NIHChestXray:split=TRAIN:root=/mnt/d/data/NIH/train_tmp\n",
      "use_volta32: False\n",
      "val_dataset_str: NIHChestXray:split=VAL:root=/mnt/d/data/NIH/test_tmp\n",
      "I20230813 21:39:27 683 dinov2 config.py:27] sqrt scaling learning rate; base: 0.004, new: 0.001\n",
      "I20230813 21:39:27 683 dinov2 config.py:34] MODEL:\n",
      "  WEIGHTS: ''\n",
      "compute_precision:\n",
      "  grad_scaler: true\n",
      "  teacher:\n",
      "    backbone:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp16\n",
      "        buffer_dtype: fp32\n",
      "    dino_head:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp16\n",
      "        buffer_dtype: fp32\n",
      "    ibot_head:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp16\n",
      "        buffer_dtype: fp32\n",
      "  student:\n",
      "    backbone:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp16\n",
      "        buffer_dtype: fp32\n",
      "    dino_head:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp32\n",
      "        buffer_dtype: fp32\n",
      "    ibot_head:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp32\n",
      "        buffer_dtype: fp32\n",
      "dino:\n",
      "  loss_weight: 1.0\n",
      "  head_n_prototypes: 65536\n",
      "  head_bottleneck_dim: 256\n",
      "  head_nlayers: 3\n",
      "  head_hidden_dim: 2048\n",
      "  koleo_loss_weight: 0.1\n",
      "ibot:\n",
      "  loss_weight: 1.0\n",
      "  mask_sample_probability: 0.5\n",
      "  mask_ratio_min_max:\n",
      "  - 0.1\n",
      "  - 0.5\n",
      "  separate_head: false\n",
      "  head_n_prototypes: 65536\n",
      "  head_bottleneck_dim: 256\n",
      "  head_nlayers: 3\n",
      "  head_hidden_dim: 2048\n",
      "train:\n",
      "  batch_size_per_gpu: 64\n",
      "  dataset_path: ImageNet:split=TRAIN\n",
      "  output_dir: /mnt/c/Users/user/Desktop/dinov2/results/NIH/dinov2_vits14/knn\n",
      "  saveckp_freq: 20\n",
      "  seed: 0\n",
      "  num_workers: 10\n",
      "  OFFICIAL_EPOCH_LENGTH: 1250\n",
      "  cache_dataset: true\n",
      "  centering: centering\n",
      "student:\n",
      "  arch: vit_small\n",
      "  patch_size: 14\n",
      "  drop_path_rate: 0.3\n",
      "  layerscale: 1.0e-05\n",
      "  drop_path_uniform: true\n",
      "  pretrained_weights: ''\n",
      "  ffn_layer: mlp\n",
      "  block_chunks: 0\n",
      "  qkv_bias: true\n",
      "  proj_bias: true\n",
      "  ffn_bias: true\n",
      "teacher:\n",
      "  momentum_teacher: 0.992\n",
      "  final_momentum_teacher: 1\n",
      "  warmup_teacher_temp: 0.04\n",
      "  teacher_temp: 0.07\n",
      "  warmup_teacher_temp_epochs: 30\n",
      "optim:\n",
      "  epochs: 100\n",
      "  weight_decay: 0.04\n",
      "  weight_decay_end: 0.4\n",
      "  base_lr: 0.004\n",
      "  lr: 0.001\n",
      "  warmup_epochs: 10\n",
      "  min_lr: 1.0e-06\n",
      "  clip_grad: 3.0\n",
      "  freeze_last_layer_epochs: 1\n",
      "  scaling_rule: sqrt_wrt_1024\n",
      "  patch_embed_lr_mult: 0.2\n",
      "  layerwise_decay: 0.9\n",
      "  adamw_beta1: 0.9\n",
      "  adamw_beta2: 0.999\n",
      "crops:\n",
      "  global_crops_scale:\n",
      "  - 0.32\n",
      "  - 1.0\n",
      "  local_crops_number: 8\n",
      "  local_crops_scale:\n",
      "  - 0.05\n",
      "  - 0.32\n",
      "  global_crops_size: 518\n",
      "  local_crops_size: 98\n",
      "evaluation:\n",
      "  eval_period_iterations: 12500\n",
      "\n",
      "I20230813 21:39:27 683 dinov2 vision_transformer.py:110] using MLP layer as FFN\n",
      "I20230813 21:39:28 683 dinov2 utils.py:35] Pretrained weights found at models/dinov2_vits14_pretrain.pth and loaded with msg: <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "args = argparse.Namespace(config_file='dinov2/configs/eval/vits14_pretrain.yaml', pretrained_weights='models/dinov2_vits14_pretrain.pth', output_dir='results/NIH/dinov2_vits14/knn', opts=[], train_dataset_str='NIHChestXray:split=TRAIN:root=/mnt/d/data/NIH/train_tmp', val_dataset_str='NIHChestXray:split=VAL:root=/mnt/d/data/NIH/test_tmp', nb_knn=[5, 20, 50, 100, 200], temperature=0.07, gather_on_cpu=False, batch_size=8, n_per_class_list=[-1], n_tries=1, ngpus=1, nodes=1, timeout=2800, partition='learnlab', use_volta32=False, comment='', exclude='')\n",
    "model, autocast_dtype = setup_and_build_model(args)\n",
    "model = ModelWithNormalize(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I20230813 21:39:31 683 dinov2 loaders.py:89] using dataset: \"NIHChestXray:split=TRAIN:root=/mnt/d/data/NIH/train_tmp\"\n",
      "I20230813 21:39:34 683 dinov2 nih_chest_xray.py:67] 86480 x-ray's are missing from TRAIN set\n",
      "I20230813 21:39:34 683 dinov2 loaders.py:94] # of dataset samples: 44\n",
      "I20230813 21:39:34 683 dinov2 loaders.py:89] using dataset: \"NIHChestXray:split=VAL:root=/mnt/d/data/NIH/test_tmp\"\n",
      "I20230813 21:39:38 683 dinov2 nih_chest_xray.py:67] 86480 x-ray's are missing from VAL set\n",
      "I20230813 21:39:38 683 dinov2 loaders.py:94] # of dataset samples: 44\n"
     ]
    }
   ],
   "source": [
    "transform = make_classification_eval_transform()\n",
    "train_dataset = make_dataset(\n",
    "    dataset_str=args.train_dataset_str,\n",
    "    transform=transform,\n",
    ")\n",
    "val_dataset = make_dataset(\n",
    "    dataset_str=args.val_dataset_str,\n",
    "    transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_str = args.train_dataset_str\n",
    "val_dataset_str = args.val_dataset_str\n",
    "batch_size = args.batch_size\n",
    "gather_on_cpu = args.gather_on_cpu\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I20230813 21:39:38 683 dinov2 loaders.py:164] sampler: none\n",
      "I20230813 21:39:38 683 dinov2 loaders.py:211] using PyTorch data loader\n",
      "I20230813 21:39:38 683 dinov2 loaders.py:224] # of batches: 6\n",
      "I20230813 21:39:39 683 dinov2 utils.py:139] Storing features into tensor of shape torch.Size([44, 384])\n",
      "I20230813 21:39:39 683 dinov2 helpers.py:103]   [0/6]  eta: 0:00:09    time: 1.540404  data: 0.497542  max mem: 160\n",
      "I20230813 21:39:42 683 dinov2 helpers.py:103]   [5/6]  eta: 0:00:00    time: 0.792999  data: 0.611803  max mem: 162\n",
      "I20230813 21:39:42 683 dinov2 helpers.py:131]  Total time: 0:00:04 (0.793415 s / it)\n",
      "I20230813 21:39:42 683 dinov2 utils.py:151] Features shape: (44, 384)\n",
      "I20230813 21:39:42 683 dinov2 utils.py:152] Labels shape: (44, 10)\n",
      "I20230813 21:39:42 683 dinov2 loaders.py:164] sampler: none\n",
      "I20230813 21:39:42 683 dinov2 loaders.py:211] using PyTorch data loader\n",
      "I20230813 21:39:42 683 dinov2 loaders.py:224] # of batches: 6\n",
      "I20230813 21:39:43 683 dinov2 utils.py:139] Storing features into tensor of shape torch.Size([44, 384])\n",
      "I20230813 21:39:43 683 dinov2 helpers.py:103]   [0/6]  eta: 0:00:03    time: 0.509384  data: 0.499772  max mem: 162\n",
      "I20230813 21:39:46 683 dinov2 helpers.py:103]   [5/6]  eta: 0:00:00    time: 0.650439  data: 0.643776  max mem: 162\n",
      "I20230813 21:39:46 683 dinov2 helpers.py:131]  Total time: 0:00:03 (0.650837 s / it)\n",
      "I20230813 21:39:46 683 dinov2 utils.py:151] Features shape: (44, 384)\n",
      "I20230813 21:39:46 683 dinov2 utils.py:152] Labels shape: (44, 10)\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.amp.autocast(dtype=autocast_dtype):\n",
    "    train_features, train_labels = extract_features(\n",
    "        model, train_dataset, batch_size, num_workers, gather_on_cpu=gather_on_cpu\n",
    "    )\n",
    "    model.eval()\n",
    "    val_features, val_labels = extract_features(\n",
    "        model, val_dataset, batch_size, num_workers, gather_on_cpu=gather_on_cpu\n",
    "    )\n",
    "\n",
    "train_features = train_features.cpu().numpy()\n",
    "train_labels = train_labels.cpu().numpy()\n",
    "val_features = val_features.cpu().numpy()\n",
    "val_labels = val_labels.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from enum import Enum\n",
    "from typing import Any, Dict, Optional\n",
    "from torchmetrics import Metric, MetricCollection\n",
    "from torchmetrics.wrappers import ClasswiseWrapper\n",
    "from torchmetrics.classification import (MultilabelAUROC, MultilabelF1Score, MultilabelAccuracy, MulticlassF1Score,\n",
    "                                        MulticlassAccuracy, MulticlassAUROC, Accuracy, BinaryF1Score, BinaryAUROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricAveraging(Enum):\n",
    "    MACRO = \"macro\"\n",
    "    MEAN_ACCURACY = \"micro\"\n",
    "    MEAN_PER_CLASS_ACCURACY = \"macro\"\n",
    "    MULTILABEL_ACCURACY = \"macro\"\n",
    "    MULTILABEL_AUROC = \"macro\"\n",
    "    PER_CLASS_ACCURACY = \"none\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_multilabel_auroc_metric(average_type: MetricAveraging, num_labels: int, labels=None):\n",
    "    metrics: Dict[str, Metric] = {\n",
    "        f\"auroc\": MultilabelAUROC(num_labels=num_labels, average=average_type.value),\n",
    "        \"class-specific\": MetricCollection({\n",
    "            \"auroc\": ClasswiseWrapper(MultilabelAUROC(num_labels=num_labels, average=None), labels=labels, prefix=\"_\"),\n",
    "        }) \n",
    "    }\n",
    "    return MetricCollection(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = build_multilabel_auroc_metric(MetricAveraging.MACRO, 10, [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in metric.values():\n",
    "    m = m.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = np.expand_dims(val_labels[0, :], axis=0)\n",
    "preds = np.expand_dims(np.array([0.7, 0.5, 0.4, 0.4, 0.4, 0.3, 0.8, 0.2, 0.1, 0.5]), axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {\"target\": torch.tensor(tar, device='cuda'), \"preds\": torch.tensor(preds, device='cuda')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]], device='cuda:0'),\n",
       " 'preds': tensor([[0.7000, 0.5000, 0.4000, 0.4000, 0.4000, 0.3000, 0.8000, 0.2000, 0.1000,\n",
       "          0.5000]], device='cuda:0', dtype=torch.float64)}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]], device='cuda:0'), 'preds': tensor([[0.7000, 0.5000, 0.4000, 0.4000, 0.4000, 0.3000, 0.8000, 0.2000, 0.1000,\n",
      "         0.5000]], device='cuda:0', dtype=torch.float64)}\n"
     ]
    }
   ],
   "source": [
    "print({**res})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric.update(**res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('auroc', MultilabelAUROC())\n",
      "('class-specific_auroc', ClasswiseWrapper(\n",
      "  (metric): MultilabelAUROC()\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "for i in metric.items():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I20230813 21:39:38 683 dinov2 loaders.py:164] sampler: none\n",
      "I20230813 21:39:38 683 dinov2 loaders.py:211] using PyTorch data loader\n",
      "I20230813 21:39:38 683 dinov2 loaders.py:224] # of batches: 6\n",
      "I20230813 21:39:39 683 dinov2 utils.py:139] Storing features into tensor of shape torch.Size([44, 384])\n",
      "I20230813 21:39:39 683 dinov2 helpers.py:103]   [0/6]  eta: 0:00:09    time: 1.540404  data: 0.497542  max mem: 160\n",
      "I20230813 21:39:42 683 dinov2 helpers.py:103]   [5/6]  eta: 0:00:00    time: 0.792999  data: 0.611803  max mem: 162\n",
      "I20230813 21:39:42 683 dinov2 helpers.py:131]  Total time: 0:00:04 (0.793415 s / it)\n",
      "I20230813 21:39:42 683 dinov2 utils.py:151] Features shape: (44, 384)\n",
      "I20230813 21:39:42 683 dinov2 utils.py:152] Labels shape: (44, 10)\n",
      "I20230813 21:39:42 683 dinov2 loaders.py:164] sampler: none\n",
      "I20230813 21:39:42 683 dinov2 loaders.py:211] using PyTorch data loader\n",
      "I20230813 21:39:42 683 dinov2 loaders.py:224] # of batches: 6\n",
      "I20230813 21:39:43 683 dinov2 utils.py:139] Storing features into tensor of shape torch.Size([44, 384])\n",
      "I20230813 21:39:43 683 dinov2 helpers.py:103]   [0/6]  eta: 0:00:03    time: 0.509384  data: 0.499772  max mem: 162\n",
      "I20230813 21:39:46 683 dinov2 helpers.py:103]   [5/6]  eta: 0:00:00    time: 0.650439  data: 0.643776  max mem: 162\n",
      "I20230813 21:39:46 683 dinov2 helpers.py:131]  Total time: 0:00:03 (0.650837 s / it)\n",
      "I20230813 21:39:46 683 dinov2 utils.py:151] Features shape: (44, 384)\n",
      "I20230813 21:39:46 683 dinov2 utils.py:152] Labels shape: (44, 10)\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.amp.autocast(dtype=autocast_dtype):\n",
    "    train_features, train_labels = extract_features(\n",
    "        model, train_dataset, batch_size, num_workers, gather_on_cpu=gather_on_cpu\n",
    "    )\n",
    "    model.eval()\n",
    "    val_features, val_labels = extract_features(\n",
    "        model, val_dataset, batch_size, num_workers, gather_on_cpu=gather_on_cpu\n",
    "    )\n",
    "\n",
    "train_features = train_features.cpu().numpy()\n",
    "train_labels = train_labels.cpu().numpy()\n",
    "val_features = val_features.cpu().numpy()\n",
    "val_labels = val_labels.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\"a\": metric}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_items([('auroc', MultilabelAUROC()), ('class-specific_auroc', ClasswiseWrapper(\n",
       "  (metric): MultilabelAUROC()\n",
       "))])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auroc': tensor(0., device='cuda:0', dtype=torch.float64),\n",
       " 'class-specific_auroc': {'_a': tensor(0., device='cuda:0', dtype=torch.float64),\n",
       "  '_b': tensor(0., device='cuda:0', dtype=torch.float64),\n",
       "  '_c': tensor(0., device='cuda:0', dtype=torch.float64),\n",
       "  '_d': tensor(0., device='cuda:0', dtype=torch.float64),\n",
       "  '_e': tensor(0., device='cuda:0', dtype=torch.float64),\n",
       "  '_f': tensor(0., device='cuda:0', dtype=torch.float64),\n",
       "  '_g': tensor(0., device='cuda:0', dtype=torch.float64),\n",
       "  '_h': tensor(0., device='cuda:0', dtype=torch.float64),\n",
       "  '_i': tensor(0., device='cuda:0', dtype=torch.float64),\n",
       "  '_j': tensor(0., device='cuda:0', dtype=torch.float64)}}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = {k: m.compute() for k, m in metric.items()}\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_method_to_nested_values(d, method_name):\n",
    "    result = {}\n",
    "    print(d)\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, MetricCollection):\n",
    "            result[key] = apply_method_to_nested_values(value, method_name)\n",
    "        else:\n",
    "            method = getattr(value, method_name)\n",
    "            result[key] = method()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': {'auroc': tensor(0., device='cuda:0', dtype=torch.float64),\n",
       "  'class-specific_auroc': {'_a': tensor(0., device='cuda:0', dtype=torch.float64),\n",
       "   '_b': tensor(0., device='cuda:0', dtype=torch.float64),\n",
       "   '_c': tensor(0., device='cuda:0', dtype=torch.float64),\n",
       "   '_d': tensor(0., device='cuda:0', dtype=torch.float64),\n",
       "   '_e': tensor(0., device='cuda:0', dtype=torch.float64),\n",
       "   '_f': tensor(0., device='cuda:0', dtype=torch.float64),\n",
       "   '_g': tensor(0., device='cuda:0', dtype=torch.float64),\n",
       "   '_h': tensor(0., device='cuda:0', dtype=torch.float64),\n",
       "   '_i': tensor(0., device='cuda:0', dtype=torch.float64),\n",
       "   '_j': tensor(0., device='cuda:0', dtype=torch.float64)}}}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Atelectasis', 'Cardiomegaly', 'Effusion', 'Emphysema', 'Fibrosis',\n",
       "       'Infiltration', 'Mass', 'No Finding', 'Nodule',\n",
       "       'Pleural_Thickening'], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLkNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m results_dict[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m {}\n\u001b[1;32m     10\u001b[0m classifier \u001b[39m=\u001b[39m MLkNN(k)\n\u001b[0;32m---> 11\u001b[0m classifier\u001b[39m.\u001b[39;49mfit(train_features, train_labels)\n\u001b[1;32m     12\u001b[0m results \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mpredict(val_features)\u001b[39m.\u001b[39mtoarray()\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(results\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m/mnt/c/Users/user/Desktop/dinov2/dinov2/eval/utils.py:387\u001b[0m, in \u001b[0;36mMLkNN.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prior_prob_true, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prior_prob_false \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_prior(\n\u001b[1;32m    384\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_label_cache\n\u001b[1;32m    385\u001b[0m )\n\u001b[1;32m    386\u001b[0m \u001b[39m# Computing the posterior probabilities\u001b[39;00m\n\u001b[0;32m--> 387\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cond_prob_true, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cond_prob_false \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_cond(\n\u001b[1;32m    388\u001b[0m     X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_label_cache\n\u001b[1;32m    389\u001b[0m )\n\u001b[1;32m    390\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/mnt/c/Users/user/Desktop/dinov2/dinov2/eval/utils.py:330\u001b[0m, in \u001b[0;36mMLkNN._compute_cond\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    324\u001b[0m cn \u001b[39m=\u001b[39m sparse\u001b[39m.\u001b[39mlil_matrix((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_labels, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mi8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    326\u001b[0m label_info \u001b[39m=\u001b[39m get_matrix_in_format(y, \u001b[39m\"\u001b[39m\u001b[39mdok\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    328\u001b[0m neighbors \u001b[39m=\u001b[39m [\n\u001b[1;32m    329\u001b[0m     a[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mignore_first_neighbours :]\n\u001b[0;32m--> 330\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mknn_\u001b[39m.\u001b[39;49mkneighbors(\n\u001b[1;32m    331\u001b[0m         X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_first_neighbours, return_distance\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m    332\u001b[0m     )\n\u001b[1;32m    333\u001b[0m ]\n\u001b[1;32m    335\u001b[0m \u001b[39mfor\u001b[39;00m instance \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_instances):\n\u001b[1;32m    336\u001b[0m     deltas \u001b[39m=\u001b[39m label_info[neighbors[instance], :]\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neighbors/_base.py:859\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    856\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    857\u001b[0m         kwds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meffective_metric_params_\n\u001b[0;32m--> 859\u001b[0m     chunked_results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\n\u001b[1;32m    860\u001b[0m         pairwise_distances_chunked(\n\u001b[1;32m    861\u001b[0m             X,\n\u001b[1;32m    862\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_X,\n\u001b[1;32m    863\u001b[0m             reduce_func\u001b[39m=\u001b[39;49mreduce_func,\n\u001b[1;32m    864\u001b[0m             metric\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meffective_metric_,\n\u001b[1;32m    865\u001b[0m             n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    866\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds,\n\u001b[1;32m    867\u001b[0m         )\n\u001b[1;32m    868\u001b[0m     )\n\u001b[1;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_method \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mball_tree\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkd_tree\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    871\u001b[0m     \u001b[39mif\u001b[39;00m issparse(X):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:2017\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   2015\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2016\u001b[0m     X_chunk \u001b[39m=\u001b[39m X[sl]\n\u001b[0;32m-> 2017\u001b[0m D_chunk \u001b[39m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[39m=\u001b[39;49mmetric, n_jobs\u001b[39m=\u001b[39;49mn_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m   2018\u001b[0m \u001b[39mif\u001b[39;00m (X \u001b[39mis\u001b[39;00m Y \u001b[39mor\u001b[39;00m Y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[39m.\u001b[39mget(\n\u001b[1;32m   2019\u001b[0m     metric, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2020\u001b[0m ) \u001b[39mis\u001b[39;00m euclidean_distances:\n\u001b[1;32m   2021\u001b[0m     \u001b[39m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[1;32m   2022\u001b[0m     \u001b[39m# i.e. \"l2\"\u001b[39;00m\n\u001b[1;32m   2023\u001b[0m     D_chunk\u001b[39m.\u001b[39mflat[sl\u001b[39m.\u001b[39mstart :: _num_samples(X) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:2195\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   2192\u001b[0m         \u001b[39mreturn\u001b[39;00m distance\u001b[39m.\u001b[39msquareform(distance\u001b[39m.\u001b[39mpdist(X, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[1;32m   2193\u001b[0m     func \u001b[39m=\u001b[39m partial(distance\u001b[39m.\u001b[39mcdist, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m-> 2195\u001b[0m \u001b[39mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1765\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1762\u001b[0m X, Y, dtype \u001b[39m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[1;32m   1764\u001b[0m \u001b[39mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 1765\u001b[0m     \u001b[39mreturn\u001b[39;00m func(X, Y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m   1767\u001b[0m \u001b[39m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[1;32m   1768\u001b[0m fd \u001b[39m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1105\u001b[0m, in \u001b[0;36mcosine_distances\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute cosine distance between samples in X and Y.\u001b[39;00m\n\u001b[1;32m   1080\u001b[0m \n\u001b[1;32m   1081\u001b[0m \u001b[39mCosine distance is defined as 1.0 minus the cosine similarity.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[39mscipy.spatial.distance.cosine : Dense matrices only.\u001b[39;00m\n\u001b[1;32m   1103\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m \u001b[39m# 1.0 - cosine_similarity(X, Y) without copy\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m S \u001b[39m=\u001b[39m cosine_similarity(X, Y)\n\u001b[1;32m   1106\u001b[0m S \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   1107\u001b[0m S \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m global_skip_validation \u001b[39m=\u001b[39m get_config()[\u001b[39m\"\u001b[39m\u001b[39mskip_parameter_validation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    186\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[1;32m    188\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1585\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1582\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1583\u001b[0m     Y_normalized \u001b[39m=\u001b[39m normalize(Y, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m-> 1585\u001b[0m K \u001b[39m=\u001b[39m safe_sparse_dot(X_normalized, Y_normalized\u001b[39m.\u001b[39;49mT, dense_output\u001b[39m=\u001b[39;49mdense_output)\n\u001b[1;32m   1587\u001b[0m \u001b[39mreturn\u001b[39;00m K\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/extmath.py:196\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m     ret \u001b[39m=\u001b[39m a \u001b[39m@\u001b[39m b\n\u001b[1;32m    195\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m--> 196\u001b[0m     sparse\u001b[39m.\u001b[39;49missparse(a)\n\u001b[1;32m    197\u001b[0m     \u001b[39mand\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(b)\n\u001b[1;32m    198\u001b[0m     \u001b[39mand\u001b[39;00m dense_output\n\u001b[1;32m    199\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(ret, \u001b[39m\"\u001b[39m\u001b[39mtoarray\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    200\u001b[0m ):\n\u001b[1;32m    201\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\u001b[39m.\u001b[39mtoarray()\n\u001b[1;32m    202\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/sparse/_base.py:1461\u001b[0m, in \u001b[0;36missparse\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1458\u001b[0m sparray\u001b[39m.\u001b[39m\u001b[39m__doc__\u001b[39m \u001b[39m=\u001b[39m _spbase\u001b[39m.\u001b[39m\u001b[39m__doc__\u001b[39m\n\u001b[0;32m-> 1461\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39missparse\u001b[39m(x):\n\u001b[1;32m   1462\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Is `x` of a sparse array type?\u001b[39;00m\n\u001b[1;32m   1463\u001b[0m \n\u001b[1;32m   1464\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[39m    False\u001b[39;00m\n\u001b[1;32m   1486\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(x, _spbase)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from dinov2.eval.utils import MLkNN\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "for k in args.nb_knn:\n",
    "    results_dict[f\"{k}\"] = {}\n",
    "\n",
    "    classifier = MLkNN(k)\n",
    "    classifier.fit(train_features, train_labels)\n",
    "    results = classifier.predict(val_features).toarray()\n",
    "    \n",
    "    print(results.shape)\n",
    "    results_dict[f\"{k}\"][\"Hamming Loss\"]  = sklearn.metrics.hamming_loss(val_labels, results)\n",
    "    results_dict[f\"{k}\"][\"Accuracy\"]  = sklearn.metrics.accuracy_score(val_labels, results)\n",
    "    results_dict[f\"{k}\"][\"mAUC Combined\"]  = sklearn.metrics.roc_auc_score(val_labels, results, average=\"macro\")\n",
    "    results_dict[f\"{k}\"][\"F1\"]  = sklearn.metrics.f1_score(val_labels, results, average=\"macro\")\n",
    "\n",
    "    # Disease-specific scores\n",
    "    disease_results = {\"AUC\": {}, \"Accuracy\": {}, \"F1\": {}}\n",
    "    for index, disease in enumerate(train_dataset.class_names):\n",
    "        disease_results[\"AUC\"][disease] =  sklearn.metrics.roc_auc_score(val_labels[:, index], results[:, index])\n",
    "        disease_results[\"Accuracy\"][disease] =  sklearn.metrics.accuracy_score(val_labels[:, index], results[:, index])\n",
    "        disease_results[\"F1\"][disease] =  sklearn.metrics.f1_score(val_labels[:, index], results[:, index])\n",
    "\n",
    "    results_dict[f\"{k}\"][\"Disease-specific\"] = disease_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
