{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import IPython \n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt \n",
    "import torchxrayvision as xrv\n",
    "\n",
    "from dinov2.data import SamplerType, make_data_loader, make_dataset\n",
    "from dinov2.data.datasets import NIHChestXray\n",
    "from dinov2.data.transforms import make_xray_classification_eval_transform, make_classification_eval_transform\n",
    "from dinov2.eval.setup import setup_and_build_model\n",
    "from dinov2.eval.utils import ModelWithNormalize, evaluate, extract_features\n",
    "from dinov2.MLkNN import MLkNN \n",
    "from dinov2.utils import show_image_from_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(config_file='dinov2/configs/eval/vits14_pretrain.yaml', pretrained_weights='models/dinov2_vits14_pretrain.pth', output_dir='results/NIH/dinov2_vits14/knn', opts=[], train_dataset_str='NIHChestXray:split=TRAIN:root=/mnt/d/data/NIH/train_tmp', val_dataset_str='NIHChestXray:split=VAL:root=/mnt/d/data/NIH/test_tmp', nb_knn=[5, 20, 50, 100, 200], temperature=0.07, gather_on_cpu=False, batch_size=8, n_per_class_list=[-1], n_tries=1, ngpus=1, nodes=1, timeout=2800, partition='learnlab', use_volta32=False, comment='', exclude='')\n",
    "model, autocast_dtype = setup_and_build_model(args)\n",
    "model = ModelWithNormalize(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = make_classification_eval_transform()\n",
    "train_dataset = make_dataset(\n",
    "    dataset_str=args.train_dataset_str,\n",
    "    transform=transform,\n",
    ")\n",
    "val_dataset = make_dataset(\n",
    "    dataset_str=args.val_dataset_str,\n",
    "    transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_str = args.train_dataset_str\n",
    "val_dataset_str = args.val_dataset_str\n",
    "batch_size = args.batch_size\n",
    "gather_on_cpu = args.gather_on_cpu\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast(dtype=autocast_dtype):\n",
    "    train_features, train_labels = extract_features(\n",
    "        model, train_dataset, batch_size, num_workers, gather_on_cpu=gather_on_cpu\n",
    "    )\n",
    "    val_features, val_labels = extract_features(\n",
    "        model, val_dataset, batch_size, num_workers, gather_on_cpu=gather_on_cpu\n",
    "    )\n",
    "\n",
    "train_features = train_features.cpu().numpy()\n",
    "train_labels = train_labels.cpu().numpy()\n",
    "val_features = val_features.cpu().numpy()\n",
    "val_labels = val_labels.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLkNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "for k in args.nb_knn:\n",
    "    classifier = MLkNN(k)\n",
    "    classifier.fit(train_features, train_labels)\n",
    "    results = classifier.predict(train_features).toarray()\n",
    "    print(f\"### for {k}-NN ###\")\n",
    "    print(\"### Hamming loss: %f\" % sklearn.metrics.hamming_loss(train_labels, results))\n",
    "    print(\"### Accuracy score: %f\" % sklearn.metrics.accuracy_score(train_labels, results))\n",
    "    print(\"### mAUC score combined: %f\" % sklearn.metrics.roc_auc_score(train_labels, results, average=\"weighted\"))\n",
    "    print(\"### F1 score: %f\" % sklearn.metrics.f1_score(train_labels, results, average=\"micro\"))\n",
    "\n",
    "    # Disease-specific scores\n",
    "    disease_results = {\"AUC\": {}, \"Accuracy\": {}, \"F1\": {}}\n",
    "    for index, disease in enumerate(train_dataset.class_names):\n",
    "        disease_results[\"AUC\"][disease] =  sklearn.metrics.roc_auc_score(train_labels[:, index], results[:, index])\n",
    "        disease_results[\"Accuracy\"][disease] =  sklearn.metrics.accuracy_score(train_labels[:, index], results[:, index])\n",
    "        disease_results[\"F1\"][disease] =  sklearn.metrics.f1_score(train_labels[:, index], results[:, index])\n",
    "    print(\"## Disease-specific AUC scores\")    \n",
    "    print(pd.DataFrame(disease_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
