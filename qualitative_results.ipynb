{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import argparse\n",
    "import IPython \n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from enum import Enum\n",
    "from typing import Callable, List, Optional, Tuple, Union\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.datasets import VisionDataset\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt \n",
    "import torchxrayvision as xrv\n",
    "\n",
    "from dinov2.models.unet import UNet\n",
    "from dinov2.data import SamplerType, make_data_loader, make_dataset\n",
    "from dinov2.data.datasets import NIHChestXray, MC\n",
    "from dinov2.data.loaders import make_data_loader\n",
    "from dinov2.data.transforms import make_segmentation_target_transform, make_segmentation_transform\n",
    "from dinov2.eval.setup import setup_and_build_model\n",
    "from dinov2.eval.utils import ModelWithIntermediateLayers, ModelWithNormalize, evaluate, extract_features\n",
    "from dinov2.eval.metrics import build_segmentation_metrics, MetricAveraging\n",
    "from dinov2.utils import show_image_from_tensor\n",
    "from dinov2.eval.segmentation import setup_decoders, DINOV2Encoder, LinearDecoder\n",
    "from fvcore.common.checkpoint import Checkpointer, PeriodicCheckpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(config_file='dinov2/configs/eval/vits14_pretrain.yaml', pretrained_weights='models/dinov2_vits14_pretrain.pth', output_dir='results/NIH/dinov2_vits14/knn', opts=[], train_dataset_str='MC:split=TRAIN:root=/mnt/z/data/MC/train', val_dataset_str='MC:split=VAL:root=/mnt/z/data/MC/test', nb_knn=[5, 20, 50, 100, 200], temperature=0.07, gather_on_cpu=False, batch_size=8, n_per_class_list=[-1], n_tries=1, ngpus=1, nodes=1, timeout=2800, partition='learnlab', use_volta32=False, comment='', exclude='')\n",
    "model, autocast_dtype = setup_and_build_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = make_segmentation_transform(resize_size=448)\n",
    "target_transform = make_segmentation_target_transform(resize_size=448)\n",
    "\n",
    "train_dataset = make_dataset(\n",
    "    dataset_str=args.train_dataset_str,\n",
    "    transform=transform,\n",
    "    target_transform=target_transform\n",
    ")\n",
    "val_dataset = make_dataset(\n",
    "    dataset_str=args.val_dataset_str,\n",
    "    transform=transform,\n",
    "    target_transform=target_transform,\n",
    ")\n",
    "\n",
    "sampler_type = SamplerType.INFINITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = model.embed_dim\n",
    "decoders, optim_param_groups = setup_decoders(\n",
    "    embed_dim,\n",
    "    [1e-6, 2e-6, 5e-6, 1e-5, 2e-5, 5e-5, 1e-4, 2e-4, 5e-4, 1e-3, 2e-3, 5e-3, 1e-2, 5e-2, 1e-1],\n",
    "    3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"models/trained_heads/segmentation_linear/model_final.pth\"\n",
    "checkpointer = Checkpointer(decoders, output_dir)\n",
    "start_iter = checkpointer.resume_or_load(output_dir, resume=True).get(\"iteration\", -1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocast_ctx = partial(torch.cuda.amp.autocast, enabled=True, dtype=autocast_dtype)\n",
    "decoder = decoders.module.decoders_dict[\"segmentor_lr_0_1000000000\"]\n",
    "feature_model = DINOV2Encoder(model, autocast_ctx=autocast_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_multipler = 50\n",
    "metric = build_segmentation_metrics(average_type=MetricAveraging.SEGMENTATION_METRICS, num_labels=3).cuda()\n",
    "result_message = \"\"\n",
    "for image, target in val_dataset:\n",
    "    image, target = image.cuda(non_blocking=True).unsqueeze(0), target.cuda(non_blocking=True).unsqueeze(0)\n",
    "    with torch.no_grad(): \n",
    "        features=model.forward_features(image)['x_norm_patchtokens']\n",
    "    logits = decoder(features)\n",
    "    logits = torch.nn.functional.interpolate(logits, size=448, mode=\"bilinear\", align_corners=False)\n",
    "    prediction = logits.argmax(dim=1)\n",
    "\n",
    "    results = metric(prediction, target)\n",
    "\n",
    "    target = target.squeeze()\n",
    "    prediction = prediction.squeeze()\n",
    "\n",
    "    concated = torch.cat((target, prediction), dim=-1)\n",
    "\n",
    "    prediction = (prediction * highlight_multipler).cpu()\n",
    "    target = (target * highlight_multipler).cpu()\n",
    "    concated = (concated.unsqueeze(0).type(torch.int32) * highlight_multipler).cpu()\n",
    "    H, W = concated.squeeze().shape\n",
    "\n",
    "    pil_image = torchvision.transforms.ToPILImage()(concated)\n",
    "    pil_image = pil_image.convert(\"L\") # Convert to Grayscale\n",
    "\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "    _, _, w, h = draw.textbbox((0, 0), \"Target\")\n",
    "    draw.text(((W-w)*0.25, H*0.025), \"Target\", fill=255)\n",
    "\n",
    "    _, _, w, h = draw.textbbox((0, 0), \"Prediction\")\n",
    "    draw.text(( (W-w) * 0.75, H*0.025), \"Prediction\", fill=255)\n",
    "\n",
    "    for m, r in dict(results).items():\n",
    "        result_message += f\"{m}: {float(r):.3f} \"\n",
    "\n",
    "    draw.text((0, 0), result_message, fill=255)\n",
    "\n",
    "    pil_image.save(\"hello.png\")\n",
    "    print(metric.compute())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
